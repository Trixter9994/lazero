# according to the generated data, we begin to process the whole shit.
# fractal fourier transform
# how to fuck with the shit?
from getFromPickleR import returnListV
import rewire
import readLikeHuman
import transformer as tr
import re
# FFT -> fucking fourier transform! fuck all of you fuck you fuck you fuck fuck fuck fuck fuck
# this is clearly not the compression algorithm.
# I give up on that fucking fractal code...
# pussy balls.
# get off my dick bitch!
# import backTrans
# cocksucker!
# bullshit. they are gonna die!
def grabber(a):
    v,s=0,[]
    for x in a:
        z=x[0][0]
        s.append(list(map((lambda y: z+y[1]+v),x)))
#        s.append(v)
        v+=len(x)-1
    return s

def fVerify(a,b,h):
    c,d=a,list(filter((lambda x: type(x)==type([])),h))
    print("__________________________________________________________________________")
    print(c)
    y=list(map((lambda x: c[x[0]:x[-1]+1]),b))
    e=[y[f]==d[f] for f in range(len(y))]
    print("__________________________________________________________________________")
    print(y)
    print("__________________________________________________________________________")
    print(d)
    return e
# shall we use graph theory?
r=returnListV(0)[0]
r1=list(map((lambda y:[y.period(),y.scale()]),list(filter((lambda x: type(x)!= int), r)))) # <- core reference.
print(r1)
# this is preprocessed data.
#21,22,30,87,110,132,137,145,190,219,227,236 unavaliable.
r0=rewire.unpacker(r)
# print(r0)
# the real
k=tr.baseIII(r0)
# print(k)
# very fucking hard to predict.
# why the fuck won't store that fuck into the fucking file?
t=list(filter((lambda x: type(x)==list), k))
#print(t)
# this is real and this is tough.
g=grabber(t) # <- this is the core index.
# print(g)
b0=readLikeHuman.Meta(0)
# l=fVerify(b0.Meta0(),g,r0)
# print(l)
# semantic search? semantic expansion?
# use fucking linear flattern method?
# how about write it into the fucking unpacker?
# we must write another version of unpacker instead?
# transform -> preprocess
# tolerance versus comprehension.
# how about store the range?
# no must get the fucking content.
# now what? extract those lines?
# structural alike? how to tell? frequency or nothing?
# let us generate the fuck. we can only extract parts of it.
# the slice?
# for x in range(len(g)):
print("________________________________________________________________")
s0=b0.content
# print(s0)
s1=[[],[]]
# relative position?
for r in range(len(s0)):
        s3=re.findall(r'\w*',s0[r])
        for s4 in s3:
                s5=[index for index, value in enumerate(s3) if value == s4]
                if s4 not in s1[0]:
                        l=len(s1[0])
                        s1[0].append(s4)
                        s1[1].append([])
                        for x in s5:
                                s1[1][l].append([r,x])
                else:
                        e=s1[0].index(s4)
                        for x in s5:
                                s1[1][e].append([r,x])
for l in range(len(s1[0])):
        print(s1[0][l],s1[1][l])
# spaces?
# print(b0.getCustomLines([0],True))
# print(b0.getCustomLines(g[0]))
# print("________________________________________________________________")
# now nothing back.
# return hidden indexes? use continualiity?
# nearst length, nearst structure?
# print(b0.extractUnread())
# fuck.
# still, how to chain it up?
# understand numbers and structures.
# number the traits.
# begin position, end position, line position.
# best algorithm than any other shit.